# Audio Signal Processing Project: Voiced/Unvoiced/Silence Detection

[ğŸ‡®ğŸ‡· ÙØ§Ø±Ø³ÛŒ](README_FA.md) | [ğŸ‡¬ğŸ‡§ English](README_EN.md)

A comprehensive audio signal processing project for identifying different speech segments in audio files using advanced signal processing techniques.

## ğŸ“‹ Project Overview

This project implements a complete audio signal processing system that identifies three types of segments in audio files:
- **Voiced segments**: Segments with clear periodicity and fundamental frequency
- **Unvoiced segments**: Noise-like segments without clear periodicity
- **Silence segments**: Segments lacking significant energy

## ğŸ› ï¸ Technologies & Skills

- **Programming Language**: Python
- **Key Libraries**:
  - NumPy: Array processing and numerical computations
  - SciPy: Signal processing and statistical analysis
  - Matplotlib: Data visualization and plotting
  - SoundFile: Reading and writing audio files (WAV, FLAC)
  - python-docx: Generating Word reports
- **Signal Processing Concepts**:
  - Time and frequency domain analysis
  - Short-term Energy
  - Zero Crossing Rate (ZCR)
  - Autocorrelation
  - Fundamental Frequency (F0)
  - Frame Segmentation

## ğŸ¯ Key Features

### 1. Initial Signal Processing
- Reading and analyzing audio files (WAV, FLAC)
- Displaying signals in time and frequency domains
- Calculating short-term energy and RMS amplitude

### 2. Feature Extraction
- **ZCR (Zero Crossing Rate)**: For distinguishing voiced and unvoiced segments
- **Short-term Energy**: For identifying silence and speech
- **Autocorrelation**: For detecting periodicity and calculating fundamental frequency

### 3. Advanced Classification
- Adaptive thresholding based on signal statistics
- Combining multiple features for higher accuracy
- Reducing False Positive and False Negative errors

### 4. Visualization & Reporting
- Professional plots for each stage
- Color-coded classification results
- Complete Word report with images

## ğŸ“Š Project Structure

```
â”œâ”€â”€ part1a_read_audio.py          # Read and display audio file
â”œâ”€â”€ part1b_short_term_energy.py   # Calculate short-term energy
â”œâ”€â”€ part2a_frame_segmentation.py  # Divide into 20ms frames
â”œâ”€â”€ part2b_zcr_calculation.py     # Calculate ZCR
â”œâ”€â”€ part2c_classification.py     # Classify using ZCR and energy
â”œâ”€â”€ part2d_autocorrelation.py    # Detect voiced using autocorrelation
â”œâ”€â”€ part2e_combined_method.py    # Combined method for final results
â”œâ”€â”€ generate_report.py            # Generate Word report
â”œâ”€â”€ README.md                     # This file (English - default)
â”œâ”€â”€ README_FA.md                  # Persian documentation
â”œâ”€â”€ README_EN.md                  # Extended English documentation
â”œâ”€â”€ PROJECT_DESCRIPTION.md        # Project description for resume/LinkedIn
â””â”€â”€ explanations.md               # Detailed Persian explanations
```

## ğŸš€ Installation

```bash
pip install -r requirements.txt
```

## ğŸ“– Usage

1. Place your audio file named `audio.flac` or `audio.wav` in the same folder (FLAC has priority)
2. Run each file in order:

```bash
python part1a_read_audio.py
python part1b_short_term_energy.py
python part2a_frame_segmentation.py
python part2b_zcr_calculation.py
python part2c_classification.py
python part2d_autocorrelation.py
python part2e_combined_method.py

# Generate Word report
python generate_report.py
```

**Note**: If the audio file is not found, each script will automatically create a sample signal for testing.

## ğŸ“ˆ Output Files

Each script saves its plots in PNG files:
- `part1a_audio_display.png` - Audio signal in time and frequency domains
- `part1b_short_term_energy.png` - Short-term energy and RMS
- `part2a_frame_segmentation.png` - Frame segmentation visualization
- `part2b_zcr_calculation.png` - ZCR variations over time
- `part2c_classification.png` - Classification based on ZCR and energy
- `part2d_autocorrelation.png` - Autocorrelation analysis
- `part2e_combined_method.png` - Combined method results
- `part2e_final_result.png` - Final result with color-coded segments

## ğŸ”¬ Technical Details

### Short-term Energy
Energy of each frame is calculated as the sum of squared samples.

### ZCR (Zero Crossing Rate)
The rate of sign changes in a frame, useful for detecting unvoiced segments.

### Autocorrelation
Used to identify periodicity in signals and can detect fundamental frequency (F0) for voiced segments.

### Classification Rules
- **Silence**: Low energy
- **Unvoiced**: Medium energy, high ZCR, weak autocorrelation
- **Voiced**: High energy, low ZCR, strong autocorrelation

## ğŸ“ Report Generation

After running all scripts, you can generate a complete Word report with all stages and images:

```bash
python generate_report.py
```

This creates a professional Word document (`Ú¯Ø²Ø§Ø±Ø´_Ù¾Ø±ÙˆÚ˜Ù‡_Ù¾Ø±Ø¯Ø§Ø²Ø´_Ø³ÛŒÚ¯Ù†Ø§Ù„_ØµÙˆØªÛŒ.docx`) including:
- All project stages
- Detailed explanations
- All images and plots
- Conclusions

## ğŸ“ Scientific Concepts

This project covers the following concepts:
- Digital Signal Processing (DSP)
- Audio signal analysis
- Acoustic feature extraction
- Pattern classification
- Data visualization

## ğŸ’¡ Applications

1. **Audio Transmission Quality**: Optimize bandwidth by identifying silence
2. **Speech Detection**: Separate speech from silence
3. **Speech Analysis**: Examine acoustic features
4. **Audio Compression**: Use classification information for better compression

## ğŸ“š Documentation Files

- **README.md**: This file (English - default for GitHub)
- **README_FA.md**: Persian usage guide
- **README_EN.md**: Extended English documentation
- **explanations.md**: Detailed Persian explanations
- **PROJECT_DESCRIPTION.md**: Project description for resume/LinkedIn

## ğŸ”§ Technical Notes

- **Sample Rate**: Supports various rates (default: 16 kHz)
- **Frame Length**: 20 milliseconds (optimal balance between accuracy and efficiency)
- **Supported Formats**: WAV, FLAC
- **Processing**: Optimized for high performance

## ğŸ“„ License

This project is developed as part of a signal processing course and can be used as a foundation for more advanced projects such as speech recognition, speaker identification, and emotion analysis.

---

**Note**: For proper Persian text display in the Word report, the 'B Nazanin' font should be installed on your system. You can modify the font in the code if needed.
